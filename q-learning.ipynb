{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29KkLSQ-QeXB",
        "outputId": "42daf1ac-f05b-451d-9b60-c992bdc9b374"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q-2UpFUZOruX"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from dataclasses import dataclass\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/yourusername/yourrepository.git\n",
        "!git clone https://github.com/geomuse/snake.git\n",
        "%cd snake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX8AB4SyuQen",
        "outputId": "c2753c30-9df2-4c0c-a9de-4258f884aceb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'snake'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 25 (delta 13), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (25/25), 9.17 KiB | 4.59 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "/content/snake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "from gym_snake_inherit import SnakeEnv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l_sriSrujd9",
        "outputId": "caba80ea-fb9c-4667-c266-769d5036a5bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "advance_snake_gym_framework.py\tgym_snake.py  united_snake.py\n",
            "advance_snake.py\t\tREADME.md\n",
            "gym_snake_inherit.py\t\tsnake.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "env = SnakeEnv()\n",
        "observation = env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    observation, reward, done, _ = env.sample()\n",
        "'''\n",
        "print('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlAG_ZPSARff",
        "outputId": "da07ff73-2c0c-4a86-d2a1-febd78af43b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = SnakeEnv()\n",
        "observation = env.reset()\n",
        "done = False\n",
        "\n",
        "# Q-learning算法\n",
        "def q_learning(env, num_episodes=1000, learning_rate=0.8, discount_factor=0.95, exploration_prob=0.2):\n",
        "    # 初始化Q值表格，记录每个状态和动作的Q值\n",
        "    num_actions = env.action_space.n\n",
        "    num_states = env.observation_space.shape[0]\n",
        "    q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            # 通过epsilon-greedy策略选择动作\n",
        "            if random.uniform(0, 1) < exploration_prob:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(q_table[state, :])\n",
        "\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            # 更新Q值函数\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + discount_factor * np.max(q_table[next_state, :])\n",
        "            try :\n",
        "              q_table[state, action] = (1 - learning_rate) * q_table[state, action] + learning_rate * target\n",
        "            except :\n",
        "              return q_table\n",
        "            state = next_state\n",
        "\n",
        "    return q_table\n",
        "\n",
        "# 训练Q值函数\n",
        "q_table = q_learning(env)"
      ],
      "metadata": {
        "id": "PGyfAvRwwS3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrGyVjY31tPD",
        "outputId": "77335749-dd87-4dab-d923-dd798282d4ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.0494047  -0.02503034 -0.00226788 -0.06052233]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " ...\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用训练好的Q值函数进行游戏\n",
        "import pygame\n",
        "pygame.init()\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = np.argmax(q_table[state, :])\n",
        "    next_state, _ , done, _ = env.step(action)\n",
        "    env.render()\n",
        "    state = next_state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oskGR_3d6DXI",
        "outputId": "9f528ead-f4ba-4ea2-e30c-6fabbb4b8fcf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pickle\n",
        "\n",
        "with open('q_table.pkl', 'wb') as f:\n",
        "    pickle.dump(q_table, f)\n",
        "\n",
        "files.download('q_table.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "x3k0LBF88EeV",
        "outputId": "a62da91b-d235-4344-f830-936ff716c9ac"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a1eb820f-0b43-44e3-8892-fe73e3b92c8e\", \"q_table.pkl\", 19353)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "env = SnakeEnv()\n",
        "observation = env.reset()\n",
        "done = False\n",
        "\n",
        "num_episodes = 1000\n",
        "num_steps_per_episode = 100\n",
        "learning_rate = 0.8\n",
        "discount_factor = 0.95\n",
        "exploration_prob = 0.2\n",
        "\n",
        "# 初始化Q值表格，记录每个状态和动作的Q值\n",
        "num_actions = env.action_space.n\n",
        "num_states = env.observation_space.shape[0]\n",
        "q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "# 定义神经网络模型，用于近似Q值函数\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(num_states,)),\n",
        "        tf.keras.layers.Dense(num_actions)\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='mse')\n",
        "    return model\n",
        "\n",
        "# 训练Q-learning算法\n",
        "def train_q_learning():\n",
        "    model = create_model()\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        state = np.reshape(state, [1, num_states])\n",
        "\n",
        "        for step in range(num_steps_per_episode):\n",
        "            # 通过epsilon-greedy策略选择动作\n",
        "            if random.uniform(0, 1) < exploration_prob:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(q_table[state, :])\n",
        "\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            next_state = np.reshape(next_state, [1, num_states])\n",
        "\n",
        "            # 更新Q值函数\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + discount_factor * np.max(q_table[next_state, :])\n",
        "            q_table[state, action] = (1 - learning_rate) * q_table[state, action] + learning_rate * target\n",
        "\n",
        "            state = next_state\n",
        "            print(reward)\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "    return model\n",
        "\n",
        "# 训练模型\n",
        "trained_model = train_q_learning()\n",
        "\n",
        "# 使用训练好的模型进行游戏\n",
        "state = env.reset()\n",
        "state = np.reshape(state, [1, num_states])\n",
        "\n",
        "for step in range(num_steps_per_episode):\n",
        "    action = np.argmax(trained_model.predict(state))\n",
        "    next_state, _, done, _ = env.step(action)\n",
        "\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "    state = np.reshape(next_state, [1, num_states])\n",
        "\n",
        "env.close()\n",
        "'''\n",
        "print('.')"
      ],
      "metadata": {
        "id": "bj2g2AzcDO_Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}